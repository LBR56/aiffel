{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 작사가 인공지능 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM 모델과 셰익스피어 데이터셋을 사용해 간단한 작사가 인공지능을 만들어 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 들어가며\n",
    "- 시퀀스? 시퀀스!\n",
    "- I 다음 am을 쓰면 반 이상은 맞더라\n",
    "- 실습\n",
    "  - 데이터 다듬기\n",
    "  - 인공지능 학습시키기\n",
    "  - 잘 만들어졌는지 평가하기\n",
    "- 프로젝트 : 멋진 작사가 만들기\n",
    "- 프로젝트 제출\n",
    "- 회고\n",
    "- Ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 들어가며"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장이란?\n",
    "\n",
    "> 생각이나 감정을 말과 글로 표현할 때 완결된 내용을 나타내는 최소의 단위"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NLP Task Site](https://app.inferkit.com/demo)\n",
    "\n",
    "[이루다](https://www.youtube.com/watch?v=vaZrU5vies4)\n",
    "\n",
    "[google 람다](https://www.youtube.com/watch?v=H0kd3XwCO4U)\n",
    "\n",
    "[악용의 가능성](https://decenter.kr/NewsView/1VFGQMBBXZ/GZ02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인공지능이 문장을 이해하는 방식과 작문을 가르치는 법을 배움!\n",
    "\n",
    "[할 수 있는 것들](https://youtu.be/I7sZVrwM6_Q?t=152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시퀀스(Sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 나열된 데이터를 의미\n",
    "- 동일한 속성을 띌 필요가 없음\n",
    "- 정렬될 필요 없음\n",
    "\n",
    "단, 인공지능이 예측하기 위해 연관성이 있어야 함\n",
    "\n",
    "- ex) [1,2,3,4,?] 여기서 ? == '사람' or 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "str은 `문법`에 의해 복잡한 연관성을 내제함 => 통계에 기반해서 접근해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계적 접근법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 통계가 어려우면 대체로 라는 어휘로 생각해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `나는 밥을 [ ]` == 먹다?\n",
    "- `알바생이 커피를 [ ]` == 만들다? vs 마시다?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수많은 데이터를 토대로 예측하는 것!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![00](img/00.png)](https://calvinfeng.gitbook.io/machine-learning-notebook/supervised-learning/recurrent-neural-network/recurrent_neural_networks#test-time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 이미지에서 앞에 시작을 뒤에는 끝을 표시하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 문장: <start> 나는 밥을 먹었다 \n",
      "Target 문장:  나는 밥을 먹었다 <end>\n"
     ]
    }
   ],
   "source": [
    "sentence = \" 나는 밥을 먹었다 \"\n",
    "\n",
    "source_sentence = \"<start>\" + sentence\n",
    "target_sentence = sentence + \"<end>\"\n",
    "\n",
    "print(\"Source 문장:\", source_sentence)\n",
    "print(\"Target 문장:\", target_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언어 모델(Language Model)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`나는`, `밥을` `먹었다`를 확률적으로 표현하면 다음과 같음\n",
    "\n",
    "- p(먹었다|나는, 밥을)\n",
    "- p(밥을|나는)\n",
    "\n",
    "즉, 앞의 확률이 많이 존재할수록 뒷 단어를 예측하기 좋아짐!\n",
    "\n",
    "- ex) p(먹었다|나는, 밥을) < p(먹었다|나는, 밥을, 맛있게)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 이야기를 수식으로 나타내면 다음과 같음\n",
    "\n",
    "P(Wn|W1,...Wn-1;th)\n",
    "\n",
    "즉, 현재 단어는 이전 모든 단어와 모델링 파라미터 th로 구현되어 있음!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import wget, os, re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셰익스피어 파일 불러오기\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
    "file_name = 'shakespeare.txt'\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "  wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen:',\n",
       " 'Before we proceed any further, hear me speak.',\n",
       " '',\n",
       " 'All:',\n",
       " 'Speak, speak.',\n",
       " '',\n",
       " 'First Citizen:',\n",
       " 'You are all resolved rather to die than to famish?',\n",
       " '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file_name, \"r\") as f:\n",
    "  raw_corpus = f.read().splitlines()\n",
    "\n",
    "raw_corpus[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공란과 화자를 제거해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before we proceed any further, hear me speak.\n",
      "Speak, speak.\n",
      "You are all resolved rather to die than to famish?\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    # 길이가 0인 문장은 건너뜁니다.\n",
    "    if len(sentence) == 0: continue   \n",
    "    # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
    "    if sentence[-1] == \":\": continue  \n",
    "    # 일단 문장 10개만 확인해 볼 겁니다.\n",
    "    if idx > 9: break   \n",
    "\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장을 일정한 수준으로 쪼개야함\n",
    "\n",
    "즉, 토큰화(Tokenize) 해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고려 사항\n",
    "- 문장부호, 대소문자, 특수문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n",
    "def preprocess_sentence(sentence):\n",
    "#   1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "#   2. 특수문자 양쪽에 공백을 넣고\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
    "\n",
    "#   3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "#   4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
    "\n",
    "#   5. 다시 양쪽 공백을 지웁니다\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "#   6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
    "    sentence = '<start> ' + sentence + ' <end>'\n",
    "    return sentence\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 소스 문장(Source Sentence)\n",
    "  - 입력 문장\n",
    "- 타겟 문장(Target Sentence)\n",
    "  - 출력 문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> before we proceed any further , hear me speak . <end>',\n",
       " '<start> speak , speak . <end>',\n",
       " '<start> you are all resolved rather to die than to famish ? <end>',\n",
       " '<start> resolved . resolved . <end>',\n",
       " '<start> first , you know caius marcius is chief enemy to the people . <end>',\n",
       " '<start> we know t , we know t . <end>',\n",
       " '<start> let us kill him , and we ll have corn at our own price . <end>',\n",
       " '<start> is t a verdict ? <end>',\n",
       " '<start> no more talking on t let it be done away , away ! <end>',\n",
       " '<start> one word , good citizens . <end>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 정제된 문장을 모을겁니다\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "  # 우리가 원하지 않는 문장은 건너뜁니다\n",
    "  if len(sentence) == 0: continue\n",
    "  if sentence[-1] == \":\": continue\n",
    "  \n",
    "  # 정제를 하고 담아주세요\n",
    "  preprocessed_sentence = preprocess_sentence(sentence)\n",
    "  corpus.append(preprocessed_sentence)\n",
    "\n",
    "# 정제된 결과를 10개만 확인해보죠\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corpus 데이터를 숫자로 변경할 필요가 있음\n",
    "\n",
    "즉, 벡터화(vectorize)할 필요가 있음\n",
    "\n",
    "- 모델이 넣기 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2  143   40 ...    0    0    0]\n",
      " [   2  110    4 ...    0    0    0]\n",
      " [   2   11   50 ...    0    0    0]\n",
      " ...\n",
      " [   2  149 4553 ...    0    0    0]\n",
      " [   2   34   71 ...    0    0    0]\n",
      " [   2  945   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x15546b160>\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
    "def tokenize(corpus):\n",
    "  tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    # 7000개 단어를 앎\n",
    "    num_words = 7000,\n",
    "    # 문장 정제는 완료함\n",
    "    filters = ' ',\n",
    "    # 단어가 없으면 unk로 변경\n",
    "    oov_token = '<unk>'\n",
    "  )\n",
    "  # 내부 단어장 만들기\n",
    "  tokenizer.fit_on_texts(corpus)\n",
    "  # corpus를 Tensor화\n",
    "  tensor = tokenizer.texts_to_sequences(corpus)\n",
    "  # 문장 뒤 패딩을 붙여 길이를 일정하게 맞춤\n",
    "  # 앞에 패딩을 원하면 pre로 변경 필요\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding = 'post')\n",
    "  \n",
    "  print(tensor, tokenizer)\n",
    "  return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.index_word[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src와 tgt 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2 143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0\n",
      "   0   0]\n",
      "[143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0   0\n",
      "   0   0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 17:22:07.792421: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 20), (256, 20)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input) #입력 최대 길이\n",
    "BATCH_SIZE = 256 # 학습 크기 단위\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE # 학습 횟수\n",
    "\n",
    "# tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "# 학습 크기 별로 \n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구조\n",
    "- embedding -> rnn1 -> rnn2 -> linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "    self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "    self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "    self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "    \n",
    "  def call(self, x):\n",
    "    out = self.embedding(x)\n",
    "    out = self.rnn_1(out)\n",
    "    out = self.rnn_2(out)\n",
    "    out = self.linear(out)\n",
    "    \n",
    "    return out\n",
    "  \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding_size가 크면 추상적 특징을 잡을 수 있음\n",
    "\n",
    "- 단 충분한 데이터가 없다면 혼란만 야기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/main/Desktop/temp/Lms/Exploration/06_LSTM/README.ipynb 셀 46\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/06_LSTM/README.ipynb#ch0000057?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49msummary()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training.py:2579\u001b[0m, in \u001b[0;36mModel.summary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested)\u001b[0m\n\u001b[1;32m   2559\u001b[0m \u001b[39m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[1;32m   2560\u001b[0m \n\u001b[1;32m   2561\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2576\u001b[0m \u001b[39m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[1;32m   2577\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2578\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[0;32m-> 2579\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2580\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mThis model has not yet been built. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2581\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2582\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mthe model on a batch of data.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   2583\u001b[0m layer_utils\u001b[39m.\u001b[39mprint_summary(\n\u001b[1;32m   2584\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2585\u001b[0m     line_length\u001b[39m=\u001b[39mline_length,\n\u001b[1;32m   2586\u001b[0m     positions\u001b[39m=\u001b[39mpositions,\n\u001b[1;32m   2587\u001b[0m     print_fn\u001b[39m=\u001b[39mprint_fn,\n\u001b[1;32m   2588\u001b[0m     expand_nested\u001b[39m=\u001b[39mexpand_nested)\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 20, 7001), dtype=float32, numpy=\n",
       "array([[[-6.73341783e-05,  2.10365310e-04,  7.37963637e-06, ...,\n",
       "          8.24388699e-05,  1.91257568e-04, -8.89830480e-05],\n",
       "        [-1.95685687e-04,  1.13518472e-05,  8.76824197e-05, ...,\n",
       "          6.08470364e-05,  3.16889578e-04, -3.40361381e-04],\n",
       "        [-1.42472913e-04, -1.83730299e-04,  2.42703158e-04, ...,\n",
       "         -2.05515928e-04,  2.86786584e-04, -3.37750156e-04],\n",
       "        ...,\n",
       "        [ 5.85960271e-03, -3.01299803e-03, -1.01899961e-03, ...,\n",
       "          2.83531612e-04, -9.54396732e-04, -1.69550534e-03],\n",
       "        [ 6.17861748e-03, -3.14934482e-03, -1.16067100e-03, ...,\n",
       "          4.10682289e-04, -1.02911994e-03, -1.85419852e-03],\n",
       "        [ 6.43536914e-03, -3.26168677e-03, -1.28763332e-03, ...,\n",
       "          5.28376782e-04, -1.09956553e-03, -1.98679441e-03]],\n",
       "\n",
       "       [[-6.73341783e-05,  2.10365310e-04,  7.37963637e-06, ...,\n",
       "          8.24388699e-05,  1.91257568e-04, -8.89830480e-05],\n",
       "        [ 2.05869103e-04,  2.13177336e-04, -2.35676067e-04, ...,\n",
       "          2.84109032e-04,  1.63721183e-04, -7.08241350e-05],\n",
       "        [ 3.04645684e-04,  2.47419637e-04, -3.53338080e-04, ...,\n",
       "          1.84611868e-04,  6.64189565e-06, -3.26119101e-04],\n",
       "        ...,\n",
       "        [ 2.92176846e-03, -2.35162210e-03, -3.19129322e-04, ...,\n",
       "          1.17345108e-03, -1.92212290e-04, -9.92947607e-04],\n",
       "        [ 3.65306507e-03, -2.57073995e-03, -4.57989227e-04, ...,\n",
       "          1.25546835e-03, -2.83737842e-04, -1.06781349e-03],\n",
       "        [ 4.31606919e-03, -2.77304533e-03, -6.02836430e-04, ...,\n",
       "          1.31826010e-03, -3.82113241e-04, -1.18376175e-03]],\n",
       "\n",
       "       [[-6.73341783e-05,  2.10365310e-04,  7.37963637e-06, ...,\n",
       "          8.24388699e-05,  1.91257568e-04, -8.89830480e-05],\n",
       "        [-5.61588822e-05,  5.56714891e-04,  1.60378753e-04, ...,\n",
       "          1.08857035e-04,  2.52735801e-04, -2.76107516e-04],\n",
       "        [-3.80148995e-05,  2.47522024e-04,  2.02506169e-04, ...,\n",
       "          1.17625481e-04,  5.34905645e-04, -7.81636336e-05],\n",
       "        ...,\n",
       "        [ 4.80867829e-03, -2.76540103e-03, -2.53080711e-04, ...,\n",
       "          6.80653146e-04, -1.09189819e-03, -1.38821534e-03],\n",
       "        [ 5.26890857e-03, -2.97421566e-03, -4.76447167e-04, ...,\n",
       "          7.79872062e-04, -1.12217758e-03, -1.62277068e-03],\n",
       "        [ 5.65552618e-03, -3.14864144e-03, -6.85222331e-04, ...,\n",
       "          8.64208210e-04, -1.15208456e-03, -1.82264228e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-6.73341783e-05,  2.10365310e-04,  7.37963637e-06, ...,\n",
       "          8.24388699e-05,  1.91257568e-04, -8.89830480e-05],\n",
       "        [-4.30436849e-05,  6.95009076e-05,  2.05280958e-05, ...,\n",
       "          9.06583737e-05,  1.22849044e-04,  8.67345516e-05],\n",
       "        [-3.64193169e-04, -2.32077218e-04, -1.92796419e-04, ...,\n",
       "         -6.28837297e-05,  1.39806070e-04,  1.27475534e-04],\n",
       "        ...,\n",
       "        [ 5.01235574e-03, -2.55830633e-03, -8.59135529e-04, ...,\n",
       "          7.92591367e-04, -9.05678957e-04, -1.37178937e-03],\n",
       "        [ 5.44036087e-03, -2.78358138e-03, -9.67609987e-04, ...,\n",
       "          8.69955868e-04, -9.97874187e-04, -1.57450500e-03],\n",
       "        [ 5.79969212e-03, -2.97463918e-03, -1.07569783e-03, ...,\n",
       "          9.31999879e-04, -1.08468777e-03, -1.75348925e-03]],\n",
       "\n",
       "       [[-6.73341783e-05,  2.10365310e-04,  7.37963637e-06, ...,\n",
       "          8.24388699e-05,  1.91257568e-04, -8.89830480e-05],\n",
       "        [-1.47028652e-04,  3.08041461e-04, -1.49849511e-04, ...,\n",
       "         -1.29549255e-04,  2.83732690e-04,  1.30082757e-04],\n",
       "        [ 6.35532633e-05,  4.83077078e-04,  2.01487928e-05, ...,\n",
       "         -4.07911837e-04,  3.02628614e-04,  5.24463889e-04],\n",
       "        ...,\n",
       "        [ 5.81113249e-03, -2.48313532e-03, -7.26594124e-04, ...,\n",
       "          1.02473353e-03, -1.00244500e-03, -1.07800483e-03],\n",
       "        [ 6.15476910e-03, -2.70191580e-03, -9.04188375e-04, ...,\n",
       "          1.10514369e-03, -1.09161297e-03, -1.31390290e-03],\n",
       "        [ 6.42946223e-03, -2.88826902e-03, -1.06515712e-03, ...,\n",
       "          1.16794580e-03, -1.16864103e-03, -1.52063125e-03]],\n",
       "\n",
       "       [[-6.73341783e-05,  2.10365310e-04,  7.37963637e-06, ...,\n",
       "          8.24388699e-05,  1.91257568e-04, -8.89830480e-05],\n",
       "        [-3.78300843e-04,  6.00831350e-04, -2.16750690e-04, ...,\n",
       "         -8.97108766e-05,  5.57379506e-04,  2.48765515e-04],\n",
       "        [-8.10277474e-04,  8.88299604e-04,  1.37007533e-04, ...,\n",
       "         -1.12056267e-04,  2.48625176e-04,  6.16409234e-04],\n",
       "        ...,\n",
       "        [ 3.53892171e-03, -1.69976940e-03,  7.64681376e-04, ...,\n",
       "          7.74682267e-05, -3.27992544e-04, -3.39906081e-04],\n",
       "        [ 4.13777586e-03, -1.98619138e-03,  4.97114903e-04, ...,\n",
       "          3.07839597e-04, -4.75152396e-04, -6.47818146e-04],\n",
       "        [ 4.66735382e-03, -2.25129537e-03,  2.25844444e-04, ...,\n",
       "          4.99421381e-04, -6.05870853e-04, -9.40410362e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  1792256   \n",
      "                                                                 \n",
      " lstm (LSTM)                 multiple                  5246976   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               multiple                  8392704   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  7176025   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,607,961\n",
      "Trainable params: 22,607,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/main/Desktop/temp/Lms/Exploration/06_LSTM/README.ipynb 셀 48\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/06_LSTM/README.ipynb#ch0000065?line=3'>4</a>\u001b[0m loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/06_LSTM/README.ipynb#ch0000065?line=4'>5</a>\u001b[0m     from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/06_LSTM/README.ipynb#ch0000065?line=5'>6</a>\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/06_LSTM/README.ipynb#ch0000065?line=6'>7</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/06_LSTM/README.ipynb#ch0000065?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mloss, optimizer\u001b[39m=\u001b[39moptimizer)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/06_LSTM/README.ipynb#ch0000065?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1217\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/def_function.py:958\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    956\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 958\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    959\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    961\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/def_function.py:780\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    778\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    779\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 780\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    781\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    783\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    784\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:3157\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3155\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3156\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 3157\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   3158\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:3557\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3553\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3554\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3556\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mmissed\u001b[39m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3557\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   3558\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mprimary[cache_key] \u001b[39m=\u001b[39m graph_function\n\u001b[1;32m   3560\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:3392\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3387\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   3388\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3389\u001b[0m ]\n\u001b[1;32m   3390\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   3391\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3392\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   3393\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   3394\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   3395\u001b[0m         args,\n\u001b[1;32m   3396\u001b[0m         kwargs,\n\u001b[1;32m   3397\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   3398\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   3399\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   3400\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   3401\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[1;32m   3402\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   3403\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   3404\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   3405\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3406\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3407\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3408\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3409\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   3410\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/framework/func_graph.py:1143\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1143\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1145\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1148\u001b[0m                                   expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/def_function.py:672\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    669\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    670\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 672\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    673\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/framework/func_graph.py:1118\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1118\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m   1119\u001b[0m       original_func,\n\u001b[1;32m   1120\u001b[0m       args,\n\u001b[1;32m   1121\u001b[0m       kwargs,\n\u001b[1;32m   1122\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m   1123\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1124\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m   1125\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1126\u001b[0m       ))\n\u001b[1;32m   1127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:445\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 445\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    446\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/3c/92085pds035_bky462x8tl0h0000gn/T/__autograph_generated_fileni5e5bvq.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:383\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    380\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 383\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    385\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:465\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 465\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training.py:867\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mreturn\u001b[39;00m outputs\n\u001b[1;32m    866\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m--> 867\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[1;32m    868\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    869\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    870\u001b[0m write_scalar_summaries(outputs, step\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39m_train_counter)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/distribute/distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1312\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1315\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1316\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/distribute/distribute_lib.py:2892\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2890\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   2891\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2892\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/distribute/distribute_lib.py:3695\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3693\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   3694\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m-> 3695\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:696\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 696\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    697\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    698\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:383\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    380\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 383\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    385\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:464\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    465\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training.py:860\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[0;32m--> 860\u001b[0m   outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[1;32m    861\u001b[0m   \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m    862\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training.py:808\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[39m# Run forward pass.\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m--> 808\u001b[0m   y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    809\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_loss(\n\u001b[1;32m    810\u001b[0m       y, y_pred, sample_weight, regularization_losses\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39mand\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/base_layer.py:1083\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1081\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1082\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m-> 1083\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1086\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/utils/traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:696\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 696\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    697\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    698\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:445\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 445\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    446\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/3c/92085pds035_bky462x8tl0h0000gn/T/__autograph_generated_filekf9y2vms.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m out \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39membedding, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m out \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mrnn_1, (ag__\u001b[39m.\u001b[39mld(out),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 12\u001b[0m out \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrnn_2, (ag__\u001b[39m.\u001b[39;49mld(out),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     13\u001b[0m out \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mlinear, (ag__\u001b[39m.\u001b[39mld(out),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:337\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    336\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 337\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    340\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:465\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 465\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/layers/recurrent.py:679\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m _standardize_args(inputs,\n\u001b[1;32m    674\u001b[0m                                                      initial_state,\n\u001b[1;32m    675\u001b[0m                                                      constants,\n\u001b[1;32m    676\u001b[0m                                                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants)\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 679\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(RNN, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    681\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    685\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/base_layer.py:1083\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1081\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1082\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m-> 1083\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1086\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/utils/traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/layers/recurrent_v2.py:1254\u001b[0m, in \u001b[0;36mLSTM.call\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         last_output, outputs, new_h, new_c, runtime \u001b[39m=\u001b[39m standard_lstm(\n\u001b[1;32m   1251\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnormal_lstm_kwargs)\n\u001b[1;32m   1252\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m       (last_output, outputs, new_h, new_c,\n\u001b[0;32m-> 1254\u001b[0m        runtime) \u001b[39m=\u001b[39m lstm_with_backend_selection(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnormal_lstm_kwargs)\n\u001b[1;32m   1256\u001b[0m   states \u001b[39m=\u001b[39m [new_h, new_c]\n\u001b[1;32m   1258\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateful:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/layers/recurrent_v2.py:1650\u001b[0m, in \u001b[0;36mlstm_with_backend_selection\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[39m# Call the normal LSTM impl and register the cuDNN impl function. The\u001b[39;00m\n\u001b[1;32m   1648\u001b[0m   \u001b[39m# grappler will kick in during session execution to optimize the graph.\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m   last_output, outputs, new_h, new_c, runtime \u001b[39m=\u001b[39m defun_standard_lstm(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m-> 1650\u001b[0m   _function_register(defun_gpu_lstm, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m   1652\u001b[0m \u001b[39mreturn\u001b[39;00m last_output, outputs, new_h, new_c, runtime\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/layers/recurrent_v2.py:1784\u001b[0m, in \u001b[0;36m_function_register\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m concrete_func \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39mget_concrete_function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1783\u001b[0m concrete_func\u001b[39m.\u001b[39madd_to_graph()\n\u001b[0;32m-> 1784\u001b[0m concrete_func\u001b[39m.\u001b[39;49madd_gradient_functions_to_graph()\n\u001b[1;32m   1785\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_func\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:2212\u001b[0m, in \u001b[0;36mConcreteFunction.add_gradient_functions_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m   2209\u001b[0m   g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m   2210\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_delayed_rewrite_functions\u001b[39m.\u001b[39mforward()\u001b[39m.\u001b[39madd_to_graph(g)\n\u001b[1;32m   2211\u001b[0m forward_function, backward_function \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 2212\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_delayed_rewrite_functions\u001b[39m.\u001b[39;49mforward_backward())\n\u001b[1;32m   2213\u001b[0m forward_function\u001b[39m.\u001b[39madd_to_graph(g)\n\u001b[1;32m   2214\u001b[0m backward_function\u001b[39m.\u001b[39madd_to_graph(g)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:700\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions.forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[39mif\u001b[39;00m forward_backward \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m   \u001b[39mreturn\u001b[39;00m forward_backward\n\u001b[0;32m--> 700\u001b[0m forward, backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_forward_backward(num_doutputs)\n\u001b[1;32m    701\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_function_pairs[num_doutputs] \u001b[39m=\u001b[39m (forward, backward)\n\u001b[1;32m    702\u001b[0m \u001b[39mreturn\u001b[39;00m forward, backward\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:761\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    758\u001b[0m     existing_outputs\u001b[39m.\u001b[39madd(capture)\n\u001b[1;32m    759\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39moutputs\u001b[39m.\u001b[39mappend(capture)\n\u001b[0;32m--> 761\u001b[0m forward_function, backward_function \u001b[39m=\u001b[39m _create_forward_backward_with_graph(\n\u001b[1;32m    762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_attrs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph, backwards_graph)\n\u001b[1;32m    763\u001b[0m \u001b[39mreturn\u001b[39;00m forward_function, backward_function\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:661\u001b[0m, in \u001b[0;36m_create_forward_backward_with_graph\u001b[0;34m(attrs, forward_graph, backwards_graph)\u001b[0m\n\u001b[1;32m    658\u001b[0m backward_function_attr \u001b[39m=\u001b[39m _parse_func_attrs(\n\u001b[1;32m    659\u001b[0m     {FORWARD_FUNCTION_ATTRIBUTE_NAME: forward_function_name})\n\u001b[1;32m    660\u001b[0m backward_function_attr\u001b[39m.\u001b[39mupdate(common_attributes)\n\u001b[0;32m--> 661\u001b[0m backward_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m    662\u001b[0m     backwards_graph, attrs\u001b[39m=\u001b[39;49mbackward_function_attr)\n\u001b[1;32m    663\u001b[0m forward_function_attr \u001b[39m=\u001b[39m _parse_func_attrs({\n\u001b[1;32m    664\u001b[0m     BACKWARD_FUNCTION_ATTRIBUTE_NAME:\n\u001b[1;32m    665\u001b[0m     backward_function\u001b[39m.\u001b[39mname})\n\u001b[1;32m    666\u001b[0m forward_function_attr\u001b[39m.\u001b[39mupdate(common_attributes)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:1593\u001b[0m, in \u001b[0;36mConcreteFunction.__init__\u001b[0;34m(self, func_graph, attrs, shared_func_graph, function_spec)\u001b[0m\n\u001b[1;32m   1587\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_garbage_collector \u001b[39m=\u001b[39m ConcreteFunctionGarbageCollector(func_graph)\n\u001b[1;32m   1589\u001b[0m \u001b[39m# Pairs of forward and backward functions used for computing gradients.\u001b[39;00m\n\u001b[1;32m   1590\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m \u001b[39m# These each get a reference to the FuncGraph deleter since they use the\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m \u001b[39m# FuncGraph directly.\u001b[39;00m\n\u001b[0;32m-> 1593\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_delayed_rewrite_functions \u001b[39m=\u001b[39m _DelayedRewriteGradientFunctions(\n\u001b[1;32m   1594\u001b[0m     func_graph, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_attrs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_garbage_collector)\n\u001b[1;32m   1595\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_order_tape_functions \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1596\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_higher_order_tape_functions \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:683\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions.__init__\u001b[0;34m(self, func_graph, attrs, func_graph_deleter)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_function_pairs \u001b[39m=\u001b[39m {}\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph \u001b[39m=\u001b[39m func_graph\n\u001b[0;32m--> 683\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function \u001b[39m=\u001b[39m _EagerDefinedFunction(\n\u001b[1;32m    684\u001b[0m     _inference_name(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph\u001b[39m.\u001b[39;49mname), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph,\n\u001b[1;32m    685\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph\u001b[39m.\u001b[39;49minputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph\u001b[39m.\u001b[39;49moutputs, attrs)\n\u001b[1;32m    686\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_attrs \u001b[39m=\u001b[39m attrs\n\u001b[1;32m    687\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:507\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.__init__\u001b[0;34m(self, name, graph, inputs, outputs, attrs)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    506\u001b[0m   context\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 507\u001b[0m   context\u001b[39m.\u001b[39;49madd_function(fn)\n\u001b[1;32m    508\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_deleter \u001b[39m=\u001b[39m _EagerDefinedFunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m    509\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_registered_on_context \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/context.py:2579\u001b[0m, in \u001b[0;36madd_function\u001b[0;34m(fdef)\u001b[0m\n\u001b[1;32m   2577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_function\u001b[39m(fdef):\n\u001b[1;32m   2578\u001b[0m   \u001b[39m\"\"\"Add a function definition to the context.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2579\u001b[0m   context()\u001b[39m.\u001b[39;49madd_function(fdef)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/context.py:1214\u001b[0m, in \u001b[0;36mContext.add_function\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[39m\"\"\"Add a function definition to the context.\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \n\u001b[1;32m   1207\u001b[0m \u001b[39mOnce added, the function (identified by its name) can be executed like any\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[39m  fn: A wrapped TF_Function (returned from TF_GraphToFunction_wrapper).\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m-> 1214\u001b[0m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_ContextAddFunction(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle, fn)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(dataset, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 잘 만들어졌는지 평가하기\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가지표로 BLEU나 ROUGE가 존재함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "  # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "  test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "  test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "  end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "  # 단어 하나씩 예측해 문장을 만듭니다\n",
    "  while True:\n",
    "    \n",
    "    # 1. 입력받은 문장의 텐서를 입력합니다\n",
    "    predict = model(test_tensor) \n",
    "    # 2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "\n",
    "    predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "    # 3. 2에서 예측된 word index를 문장 뒤에 붙입니다 \n",
    "    test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "    \n",
    "    # 4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    if predict_word.numpy()[0] == end_token: break\n",
    "    if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "  generated = \"\"\n",
    "  # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "  for word_index in test_tensor[0].numpy():\n",
    "      generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "  return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> he , i ll not , and i have the <unk> , <end> '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> he\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 : 멋진 작사가 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그럴듯한 문장?\n",
    "- 전처리(특수문자 제거, 토크나이저 생성, 패딩처리)\n",
    "- validation loss 2.2 이하"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ref"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
