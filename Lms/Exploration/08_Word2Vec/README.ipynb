{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화리뷰 텍스트 감성분석하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imdb 영화 리뷰 평점 데이터를 토대로 사용자들의 리뷰 감성을 분류해 보는 실용적인 텍스트 분류 모델을 구현해 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 들어가며\n",
    "- 텍스트 감정분석으 유용성\n",
    "- 텍스트 데이터의 특징\n",
    "  - 텍스트를 숫자로 표현하는 방법\n",
    "  - Embedding 레이어의 등장\n",
    "- 시퀀스 데이터를 다루는 RNN\n",
    "- 꼭 RNN이어야 할까?\n",
    "- IMDB 영화리뷰 감성분석\n",
    "  - IMDB 데이터셋 분석\n",
    "  - 딥러닝 모델 설계와 훈련\n",
    "  - Word2Vec의 적용\n",
    "- 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 들어가며"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RNN(Recurrent Neural Network)\n",
    "- CNN(Convolutional Neural Network)\n",
    "= 감성분석(sentiment analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 감정분석으 유용성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 긍부정 분류(Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생각해 봐야하는 것\n",
    "\n",
    " - 텍스트 데이터 -> 정보적 특성과 가치\n",
    "  - 데이터가 많고 얻기 쉬움\n",
    "  - 실시간 트렌드 확인이 쉬움\n",
    " - 감성분석 -> 데이터 분석업무에 어떤 도움\n",
    " - 기술적 어려움\n",
    " - 딥러닝이 있으면 좋은 점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 데이터의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트를 숫자로 표현하는 방법\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ~ Z를 임의 숫자를 부여하면, A - B는 가깝고 A - Z는 먼 관계임\n",
    "\n",
    "실제로는 그렇지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS> <UNUSED> the and\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding 레이어의 등장\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어에 맞는 벡터를 연결해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.03329147  0.0126563  -0.04954543  0.03777173]\n",
      "  [ 0.03717894 -0.03838403  0.03353074  0.04650721]\n",
      "  [ 0.02710657 -0.01536978  0.02249426  0.00245017]\n",
      "  [-0.02313789 -0.04396867 -0.00793017 -0.03829795]\n",
      "  [ 0.02239207 -0.02063811  0.01889951 -0.03266783]]\n",
      "\n",
      " [[-0.03329147  0.0126563  -0.04954543  0.03777173]\n",
      "  [ 0.03717894 -0.03838403  0.03353074  0.04650721]\n",
      "  [ 0.04507843  0.0458784  -0.00094122 -0.01932559]\n",
      "  [-0.04568586 -0.01286471 -0.02395915 -0.0338795 ]\n",
      "  [ 0.02239207 -0.02063811  0.01889951 -0.03266783]]\n",
      "\n",
      " [[-0.03329147  0.0126563  -0.04954543  0.03777173]\n",
      "  [ 0.04616046 -0.02890399  0.03578175 -0.04112979]\n",
      "  [ 0.03717894 -0.03838403  0.03353074  0.04650721]\n",
      "  [ 0.02710657 -0.01536978  0.02249426  0.00245017]\n",
      "  [-0.02791373  0.03956206 -0.00843602 -0.00818193]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# tf.keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype=object)\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시퀀스 데이터를 다루는 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stateful, Stateless\n",
    "\n",
    "Stateful한 레이어인 LSTM을 쓰면 좋음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 4)           40        \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 8)                 416       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 꼭 RNN이어야 할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN도 가능함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 4)           40        \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, None, 16)          464       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, None, 16)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, None, 16)          1808      \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 16)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D()) # 전체 문장에서 가장 중요한 값을 뽑아냄\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 영화리뷰 감성분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB 데이터셋 분석\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 모델 설계와 훈련\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 16)          160000    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, None, 16)          1808      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, None, 16)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, None, 16)          1808      \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 16)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,761\n",
      "Trainable params: 163,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D()) # 전체 문장에서 가장 중요한 값을 뽑아냄\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 8s 228ms/step - loss: 0.6923 - accuracy: 0.5365 - val_loss: 0.6904 - val_accuracy: 0.5975\n",
      "Epoch 2/20\n",
      "22/30 [=====================>........] - ETA: 1s - loss: 0.6819 - accuracy: 0.6483"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/main/Desktop/temp/Lms/Exploration/08_Word2Vec/README.ipynb 셀 42\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/08_Word2Vec/README.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/08_Word2Vec/README.ipynb#X56sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/08_Word2Vec/README.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/08_Word2Vec/README.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m epochs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m  \u001b[39m# 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/08_Word2Vec/README.ipynb#X56sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(partial_x_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/08_Word2Vec/README.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                     partial_y_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/08_Word2Vec/README.ipynb#X56sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/08_Word2Vec/README.ipynb#X56sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/08_Word2Vec/README.ipynb#X56sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(x_val, y_val),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/main/Desktop/temp/Lms/Exploration/08_Word2Vec/README.ipynb#X56sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1217\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    940\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   3131\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1960\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    599\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    601\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    602\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    604\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.6994 - accuracy: 0.8430 - 2s/epoch - 2ms/step\n",
      "[0.6994262337684631, 0.8430399894714355]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec의 적용\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = 'data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04708694,  0.03804182, -0.03640002,  0.05543265,  0.07460881,\n",
       "        0.01458423,  0.04743908, -0.00952673, -0.00965919, -0.06802487,\n",
       "       -0.04349798, -0.00760116,  0.01437022,  0.05059891,  0.03181319,\n",
       "        0.03690112], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bud', 0.8766761422157288),\n",
       " ('harry', 0.8697815537452698),\n",
       " ('deep', 0.8554359078407288),\n",
       " ('30s', 0.8525770902633667),\n",
       " ('braveheart', 0.8489047884941101),\n",
       " ('keanu', 0.8398526310920715),\n",
       " ('unforgettable', 0.8190216422080994),\n",
       " ('dominic', 0.8165996670722961),\n",
       " ('reeves', 0.8163425922393799),\n",
       " ('jarring', 0.8104796409606934)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-train 된 데이터를 읽어오자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = 'data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 580, 300)          3000000   \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 574, 16)           33616     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 114, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 108, 16)           1808      \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 16)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 55s 2s/step - loss: 0.6989 - accuracy: 0.5141 - val_loss: 0.6920 - val_accuracy: 0.5343\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 46s 2s/step - loss: 0.6881 - accuracy: 0.5453 - val_loss: 0.6860 - val_accuracy: 0.5541\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 44s 1s/step - loss: 0.6629 - accuracy: 0.6011 - val_loss: 0.6482 - val_accuracy: 0.6314\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 43s 1s/step - loss: 0.5799 - accuracy: 0.7151 - val_loss: 0.5440 - val_accuracy: 0.7247\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 44s 1s/step - loss: 0.4076 - accuracy: 0.8317 - val_loss: 0.3656 - val_accuracy: 0.8419\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 44s 1s/step - loss: 0.2729 - accuracy: 0.8901 - val_loss: 0.3157 - val_accuracy: 0.8660\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 44s 1s/step - loss: 0.1981 - accuracy: 0.9277 - val_loss: 0.3098 - val_accuracy: 0.8677\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 44s 1s/step - loss: 0.1434 - accuracy: 0.9547 - val_loss: 0.3092 - val_accuracy: 0.8719\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 45s 1s/step - loss: 0.1016 - accuracy: 0.9725 - val_loss: 0.3278 - val_accuracy: 0.8701\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 44s 1s/step - loss: 0.0678 - accuracy: 0.9851 - val_loss: 0.3779 - val_accuracy: 0.8670\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 44s 1s/step - loss: 0.0393 - accuracy: 0.9927 - val_loss: 0.3798 - val_accuracy: 0.8680\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 44s 1s/step - loss: 0.0242 - accuracy: 0.9981 - val_loss: 0.4026 - val_accuracy: 0.8686\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 44s 1s/step - loss: 0.0154 - accuracy: 0.9992 - val_loss: 0.4314 - val_accuracy: 0.8665\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 44s 1s/step - loss: 0.0105 - accuracy: 0.9995 - val_loss: 0.4507 - val_accuracy: 0.8671\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 45s 1s/step - loss: 0.0072 - accuracy: 0.9998 - val_loss: 0.4669 - val_accuracy: 0.8679\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 46s 2s/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.4910 - val_accuracy: 0.8665\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 43s 1s/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.4957 - val_accuracy: 0.8672\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 48s 2s/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.5144 - val_accuracy: 0.8667\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5255 - val_accuracy: 0.8677\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 49s 2s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.8672\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 15s - loss: 0.5770 - accuracy: 0.8606 - 15s/epoch - 20ms/step\n",
      "[0.5770000219345093, 0.8606399893760681]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
