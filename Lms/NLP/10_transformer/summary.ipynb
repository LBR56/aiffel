{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer로 번역기 만들기"
      ],
      "metadata": {
        "id": "kTn7tlu0M3pt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "트랜스포머를 이용해 번역기를 만들어 본다. 먼저 내부 모듈을 하나하나 구현한 후, 조립하여 완성한다. 완성된 번역기를 테스트해 본다."
      ],
      "metadata": {
        "id": "-qshiGE7M4dC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 들어가며\n",
        "- 내부 모듈 구현하기\n",
        "- 모듈 조립하기\n",
        "- 모델 밖의 조력자들"
      ],
      "metadata": {
        "id": "1Sv8joC3M6WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 들어가며"
      ],
      "metadata": {
        "id": "Q04VJZHjNA2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkWLKk1VMwo0",
        "outputId": "916659dc-ace8-40c1-954c-cd95e6cde3c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n",
            "Fetched 9,604 kB in 1s (9,038 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 159447 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 내부 모듈 구현하기"
      ],
      "metadata": {
        "id": "lwWgomaANe6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 입력\n",
        "- source & target embedding\n",
        "- positional encoding\n",
        "- multi-head attention\n",
        "  - split head\n",
        "  - masking for masked attention\n",
        "  - scaled dot product attention\n",
        "  - combine heads\n",
        "- residual connection\n",
        "- layer normalization\n",
        "- position-wise feed-forward network\n",
        "- output linear layer"
      ],
      "metadata": {
        "id": "62Zf5ef1RInM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import random\n",
        "\n",
        "import seaborn # Attention 시각화를 위해 필요!\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLm28wsLQ3pd",
        "outputId": "f2ff0eda-d6f4-4cb5-ddca-45aeb4430312"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Encoding"
      ],
      "metadata": {
        "id": "hCV3clKVNgrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(pos, d_model):\n",
        "  def cal_angle(position, i):\n",
        "    return position / np.power(10000, int(i) / d_model)\n",
        "\n",
        "  def get_posi_angle_vec(position):\n",
        "    return [cal_angle(position, i) for i in range(d_model)]\n",
        "\n",
        "  sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
        "  sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
        "  sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
        "  return sinusoid_table"
      ],
      "metadata": {
        "id": "PGVzD2knQ1jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Head Attention"
      ],
      "metadata": {
        "id": "r-9BLsPgR0WM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2lpIXB5AR3EM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "        \n",
        "    self.depth = d_model // self.num_heads\n",
        "        \n",
        "    self.W_q = tf.keras.layers.Dense(d_model)\n",
        "    self.W_k = tf.keras.layers.Dense(d_model)\n",
        "    self.W_v = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    self.linear = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def scaled_dot_product_attention(self, Q, K, V, mask):\n",
        "    d_k = tf.cast(K.shape[-1], tf.float32)\n",
        "    QK = tf.matmul(Q, K, transpose_b=True)\n",
        "\n",
        "    scaled_qk = QK / tf.math.sqrt(d_k)\n",
        "\n",
        "    if mask is not None: scaled_qk += (mask * -1e9)  \n",
        "\n",
        "    attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
        "    out = tf.matmul(attentions, V)\n",
        "\n",
        "    return out, attentions\n",
        "          \n",
        "\n",
        "  def split_heads(self, x):\n",
        "    batch_size = x.shape[0]\n",
        "    split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    return split_x\n",
        "\n",
        "  def combine_heads(self, x):\n",
        "    batch_size = x.shape[0]\n",
        "    combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
        "\n",
        "    return combined_x\n",
        "\n",
        "      \n",
        "  def call(self, Q, K, V, mask):\n",
        "    WQ = self.W_q(Q)\n",
        "    WK = self.W_k(K)\n",
        "    WV = self.W_v(V)\n",
        "    \n",
        "    WQ_splits = self.split_heads(WQ)\n",
        "    WK_splits = self.split_heads(WK)\n",
        "    WV_splits = self.split_heads(WV)\n",
        "        \n",
        "    out, attention_weights = self.scaled_dot_product_attention(\n",
        "        WQ_splits, WK_splits, WV_splits, mask)\n",
        "                \n",
        "    out = self.combine_heads(out)\n",
        "    out = self.linear(out)\n",
        "            \n",
        "    return out, attention_weights"
      ],
      "metadata": {
        "id": "eXehz_DdSCXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Position-wise Feed-Forward Network"
      ],
      "metadata": {
        "id": "TlqKtczPSrN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, d_ff):\n",
        "    super(PoswiseFeedForwardNet, self).__init__()\n",
        "    self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
        "    self.w_2 = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def call(self, x):\n",
        "    out = self.w_1(x)\n",
        "    out = self.w_2(out)\n",
        "        \n",
        "    return out"
      ],
      "metadata": {
        "id": "N71pRzIIS0mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모듈 조립하기"
      ],
      "metadata": {
        "id": "X7Amyrc_S6We"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## encoder"
      ],
      "metadata": {
        "id": "3IOq-gZ3S6OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, n_heads, d_ff, dropout):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
        "    self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "    self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "      \n",
        "  def call(self, x, mask):\n",
        "\n",
        "    \"\"\"\n",
        "    Multi-Head Attention\n",
        "    \"\"\"\n",
        "    residual = x\n",
        "    out = self.norm_1(x) # normalization 위치 이슈\n",
        "    out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
        "    out = self.dropout(out)\n",
        "    out += residual\n",
        "    \n",
        "    \"\"\"\n",
        "    Position-Wise Feed Forward Network\n",
        "    \"\"\"\n",
        "    residual = out\n",
        "    out = self.norm_2(out)\n",
        "    out = self.ffn(out)\n",
        "    out = self.dropout(out)\n",
        "    out += residual\n",
        "    \n",
        "    return out, enc_attn"
      ],
      "metadata": {
        "id": "TCqwKe6nTUoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Normalization 위치 관련 논문](https://arxiv.org/pdf/2002.04745.pdf)"
      ],
      "metadata": {
        "id": "6dKMFyFeUcw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## decoder"
      ],
      "metadata": {
        "id": "Jgmf6LYjUqZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "    self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "    self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "    \n",
        "  def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "    \"\"\"\n",
        "    Masked Multi-Head Attention\n",
        "    \"\"\"\n",
        "    residual = x\n",
        "    out = self.norm_1(x)\n",
        "    out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
        "    out = self.dropout(out)\n",
        "    out += residual\n",
        "\n",
        "    \"\"\"\n",
        "    Multi-Head Attention\n",
        "    \"\"\"\n",
        "    residual = out\n",
        "    out = self.norm_2(out)\n",
        "    out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)\n",
        "    out = self.dropout(out)\n",
        "    out += residual\n",
        "    \n",
        "    \"\"\"\n",
        "    Position-Wise Feed Forward Network\n",
        "    \"\"\"\n",
        "    residual = out\n",
        "    out = self.norm_3(out)\n",
        "    out = self.ffn(out)\n",
        "    out = self.dropout(out)\n",
        "    out += residual\n",
        "\n",
        "    return out, dec_attn, dec_enc_attn"
      ],
      "metadata": {
        "id": "1JTuYWIjUrq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, n_layers, d_model, n_heads, d_ff, dropout):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.n_layers = n_layers\n",
        "    self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)]\n",
        "      \n",
        "  def call(self, x, mask):\n",
        "    out = x\n",
        "\n",
        "    enc_attns = list()\n",
        "    for i in range(self.n_layers):\n",
        "      out, enc_attn = self.enc_layers[i](out, mask)\n",
        "      enc_attns.append(enc_attn)\n",
        "    \n",
        "    return out, enc_attns"
      ],
      "metadata": {
        "id": "rhTOP0PbWDUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, n_layers, d_model, n_heads, d_ff, dropout):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.n_layers = n_layers\n",
        "    self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)]\n",
        "                            \n",
        "                            \n",
        "  def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "      out = x\n",
        "  \n",
        "      dec_attns = list()\n",
        "      dec_enc_attns = list()\n",
        "      for i in range(self.n_layers):\n",
        "        out, dec_attn, dec_enc_attn = \\\n",
        "        self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
        "\n",
        "        dec_attns.append(dec_attn)\n",
        "        dec_enc_attns.append(dec_enc_attn)\n",
        "\n",
        "      return out, dec_attns, dec_enc_attns"
      ],
      "metadata": {
        "id": "-RnwDe2hWTQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer 완성"
      ],
      "metadata": {
        "id": "q3IQcPzPWDEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, n_layers, d_model, n_heads, d_ff, src_vocab_size, tgt_vocab_size, pos_len, dropout=0.2, shared=True):\n",
        "    super(Transformer, self).__init__()\n",
        "    self.d_model = tf.cast(d_model, tf.float32)\n",
        "\n",
        "    self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
        "    self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "    self.pos_encoding = positional_encoding(pos_len, d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "    self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "\n",
        "    self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
        "\n",
        "    self.shared = shared\n",
        "\n",
        "    if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
        "\n",
        "  def embedding(self, emb, x):\n",
        "    seq_len = x.shape[1]\n",
        "    out = emb(x)\n",
        "\n",
        "    if self.shared: out *= tf.math.sqrt(self.d_model)\n",
        "\n",
        "    out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
        "    out = self.dropout(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "        \n",
        "  def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
        "    enc_in = self.embedding(self.enc_emb, enc_in)\n",
        "    dec_in = self.embedding(self.dec_emb, dec_in)\n",
        "\n",
        "    enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
        "    \n",
        "    dec_out, dec_attns, dec_enc_attns = \\\n",
        "    self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
        "    \n",
        "    logits = self.fc(dec_out)\n",
        "    \n",
        "    return logits, enc_attns, dec_attns, dec_enc_attns"
      ],
      "metadata": {
        "id": "zsVpB5nFWnsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 밖의 조력자들"
      ],
      "metadata": {
        "id": "rqmULWeOXIdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masking"
      ],
      "metadata": {
        "id": "G5HV5dkTXKF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def generate_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def generate_causality_mask(src_len, tgt_len):\n",
        "  mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
        "  return tf.cast(mask, tf.float32)\n",
        "\n",
        "def generate_masks(src, tgt):\n",
        "  enc_mask = generate_padding_mask(src)\n",
        "  dec_mask = generate_padding_mask(tgt)\n",
        "\n",
        "  dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
        "  dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
        "\n",
        "  dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
        "  dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
        "\n",
        "  return enc_mask, dec_enc_mask, dec_mask"
      ],
      "metadata": {
        "id": "VRB4PurRXNiQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch, length = 16, 20\n",
        "src_padding = 5\n",
        "tgt_padding = 15\n",
        "\n",
        "src_pad = tf.zeros(shape=(batch, src_padding))\n",
        "tgt_pad = tf.zeros(shape=(batch, tgt_padding))\n",
        "\n",
        "sample_data = tf.ones(shape=(batch, length))\n",
        "\n",
        "sample_src = tf.concat([sample_data, src_pad], axis=-1)\n",
        "sample_tgt = tf.concat([sample_data, tgt_pad], axis=-1)\n",
        "\n",
        "enc_mask, dec_enc_mask, dec_mask = \\\n",
        "generate_masks(sample_src, sample_tgt)\n",
        "\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "\n",
        "ax1 = fig.add_subplot(131)\n",
        "ax2 = fig.add_subplot(132)\n",
        "ax3 = fig.add_subplot(133)\n",
        "\n",
        "ax1.set_title('1) Encoder Mask')\n",
        "ax2.set_title('2) Encoder-Decoder Mask')\n",
        "ax3.set_title('3) Decoder Mask')\n",
        "\n",
        "ax1.imshow(enc_mask[:3, 0, 0].numpy(), cmap='Dark2')\n",
        "ax2.imshow(dec_enc_mask[0, 0].numpy(), cmap='Dark2')\n",
        "ax3.imshow(dec_mask[0, 0].numpy(), cmap='Dark2')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "gk3EiLHrXSYR",
        "outputId": "3d50f0a0-7a28-4fff-bce5-9c4f2243408c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate Schedualer"
      ],
      "metadata": {
        "id": "Y2KDuwRgZ56k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(LearningRateScheduler, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.warmup_steps = warmup_steps\n",
        "  \n",
        "  def __call__(self, step):\n",
        "    arg1 = step ** -0.5\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "learning_rate = LearningRateScheduler(512)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "C9G1y--9YWvE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project"
      ],
      "metadata": {
        "id": "r6FbJu3yaRrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "import numpy\n",
        "import matplotlib"
      ],
      "metadata": {
        "id": "o9RBejIiaT5Y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EigavJPuaYEY",
        "outputId": "4548c37f-6181-4a53-e387-f253bfc1ac74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-02 06:55:36--  https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz [following]\n",
            "--2022-10-02 06:55:37--  https://raw.githubusercontent.com/jungyeul/korean-parallel-corpora/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8718893 (8.3M) [application/octet-stream]\n",
            "Saving to: ‘korean-english-park.train.tar.gz’\n",
            "\n",
            "korean-english-park 100%[===================>]   8.31M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-10-02 06:55:37 (142 MB/s) - ‘korean-english-park.train.tar.gz’ saved [8718893/8718893]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzvf korean-english-park.train.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NphbwTa9aqTT",
        "outputId": "349250b2-1c97-4b93-e191-468714c4f068"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "korean-english-park.train.en\n",
            "korean-english-park.train.ko\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '.'\n",
        "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
        "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
        "\n",
        "# 데이터 정제 및 토큰화\n",
        "def clean_corpus(kor_path, eng_path):\n",
        "  with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
        "  with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
        "  assert len(kor) == len(eng)\n",
        "  kor = set(kor)\n",
        "  eng = set(eng)\n",
        "\n",
        "  return cleaned_corpus\n",
        "\n",
        "cleaned_corpus = clean_corpus(kor_path, eng_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "gXkRUbjZeq_d",
        "outputId": "3cd04652-737e-43f2-f2c7-d1d5edd4dae3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-de794858a87a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcleaned_corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcleaned_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkor_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-de794858a87a>\u001b[0m in \u001b[0;36mclean_corpus\u001b[0;34m(kor_path, eng_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# [[YOUR CODE]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcleaned_corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcleaned_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkor_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cleaned_corpus' is not defined"
          ]
        }
      ]
    }
  ]
}